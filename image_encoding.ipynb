{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged into Roboflow. To make a different login,run roboflow.login(force=True).\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in data/coco-128 to coco:: 100%|██████████| 26370/26370 [00:05<00:00, 4946.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to data/coco-128 in coco:: 100%|██████████| 386/386 [00:02<00:00, 170.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<roboflow.core.dataset.Dataset at 0x7f8303acba50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import roboflow\n",
    "\n",
    "roboflow.login()\n",
    "\n",
    "roboflow.download_dataset(dataset_url=\"https://universe.roboflow.com/team-roboflow/coco-128/dataset/2\", model_format=\"coco\", location=\"data/coco-128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, preprocess):\n",
    "        self.image_paths = image_paths\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = self.preprocess(image)\n",
    "        return image\n",
    "\n",
    "def get_data_paths(dir: str | list[str], data_formats: list, prefix: str = '') -> list[str]:\n",
    "    \"\"\"\n",
    "    Get list of files in a folder that have a file extension in the data_formats.\n",
    "\n",
    "    Args:\n",
    "      dir (str | list[str]): Dir or list of dirs containing data.\n",
    "      data_formats (list): List of file extensions. Ex: ['jpg', 'png']\n",
    "      prefix (str): Prefix for logging messages.\n",
    "\n",
    "    Returns:\n",
    "      A list of strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = []  # data files\n",
    "        for d in dir if isinstance(dir, list) else [dir]:\n",
    "            p = Path(d)\n",
    "            if p.is_dir():\n",
    "                f += glob.glob(str(p / '**' / '*.*'), recursive=True)\n",
    "            else:\n",
    "                raise FileNotFoundError(f'{prefix}{p} does not exist')\n",
    "        data_files = sorted(x for x in f if x.split('.')[-1].lower() in data_formats)\n",
    "        return data_files\n",
    "    except Exception as e:\n",
    "        raise Exception(f'{prefix}Error loading data from {dir}: {e}') from e\n",
    "\n",
    "def get_image_embeddings(data_dir, model_name=\"ViT-B/32\", batch_size=32, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Load the CLIP model\n",
    "    model, preprocess = clip.load(model_name, device=device)\n",
    "    \n",
    "    # Create a dataset and dataloader\n",
    "    image_paths = get_data_paths(data_dir, data_formats=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    print(f\"Found {len(image_paths)} images.\")\n",
    "    dataset = ImageDataset(image_paths, preprocess)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    # List to store image embeddings\n",
    "    image_embeddings = []\n",
    "\n",
    "    # Process images in batches\n",
    "    with torch.no_grad():\n",
    "        for images in dataloader:\n",
    "            images = images.to(device)\n",
    "            embeddings = model.encode_image(images)\n",
    "            embeddings /= embeddings.norm(dim=-1, keepdim=True)\n",
    "            image_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    image_embeddings = np.vstack(image_embeddings)\n",
    "    \n",
    "    return image_embeddings, image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_image_embeddings(data_dir, output_embedding_file=\"image_embeddings.npy\", output_paths_file=\"image_paths.txt\", model_name=\"ViT-B/32\", batch_size=32, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    # Get image embeddings\n",
    "    image_embeddings, image_paths = get_image_embeddings(data_dir, model_name=model_name, batch_size=batch_size, device=device)\n",
    "\n",
    "    # Save the embeddings and paths\n",
    "    np.save(output_embedding_file, image_embeddings)\n",
    "    with open(output_paths_file, \"w\") as f:\n",
    "        for path in image_paths:\n",
    "            f.write(f\"{path}\\n\")\n",
    "\n",
    "    print(\"Image encoding complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:23<00:00, 15.2MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 378 images.\n",
      "Image encoding complete.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "data_dir = \"data/coco-128\"\n",
    "process_and_save_image_embeddings(data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrcinna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
